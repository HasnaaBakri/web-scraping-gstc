# Web Scraping (GSTC PDF Downloader)

This project contains organized scripts for scraping PDF links from the [Ø§Ù„Ø£Ù…Ø§Ù†Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¬Ø§Ù† Ø§Ù„Ø²ÙƒÙˆÙŠØ© Ùˆ Ø§Ù„Ø¶Ø±ÙŠØ¨ÙŠØ© Ùˆ Ø§Ù„Ø¬Ù…Ø±ÙƒÙŠØ©](https://gstc.gov.sa/ar/Decisions/Pages/decisions.aspx?year=2020&committee=&classification=&PageIndex=1)) website and downloading them into structured folders.

## ðŸ“ Project Structure

```
web-scraping-collection/
â”œâ”€â”€ data/                     # Stores scraped link files and downloaded PDFs
â”‚   â”œâ”€â”€ gstc_pdf_links_2020.txt
â”‚   â””â”€â”€ gstc_pdf_links_2021.txt
â”œâ”€â”€ scripts/                  # Contains Python scraping and downloading notebooks
â”‚   â”œâ”€â”€ scrape_links.ipynb    # Step 1: Scrapes PDF links
â”‚   â””â”€â”€ download_pdfs.ipynb   # Step 2: Downloads PDFs from links
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ðŸ Set Up Instructions

### 1. Create and activate a virtual environment

**Windows:**
```bash
python -m venv .venv
.venv\Scripts\activate
```

### 2. Install required packages

```bash
pip install -r requirements.txt
```

> Make sure you have Chrome and [ChromeDriver](https://sites.google.com/a/chromium.org/chromedriver/) installed and accessible in your PATH.

---

## ðŸš€ How to Use

### Step 1: Scrape PDF Links

Run `scrape_links.ipynb` notebook first. This will:
- Open GSTC website pages using Selenium.
- Collect all `.pdf` links.
- Save them to text files under the `data/` folder, like:
  - `gstc_pdf_links_2020.txt`
  - `gstc_pdf_links_2021.txt`

### Step 2: Download the PDFs

Run `download_pdfs.ipynb` notebook. It will:
- Read the saved link files.
- Create folders by year inside `data/`.
- Download each PDF in chunks with progress bars using `tqdm`.

---

## ðŸ“Œ Notes

- The `data/` folder must be at the root of the project.
- All downloaded PDFs are saved inside `data/<year>/` folders.
- You can edit the list of years and number of pages in `scrape_links.ipynb`.
- URLs containing `"E-service-guideline"` are filtered out.

---
